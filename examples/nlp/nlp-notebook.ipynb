{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "1469e268",
            "metadata": {},
            "source": [
                "# Język naturalny w inżynierii\n",
                "\n",
                "Przetwarzanie języka naturalnego (NLP) umożliwia komputerom rozumienie, interpretację i generowanie ludzkiego języka. Istnieją trzy fundamentalne powody, dla których komputery wykonują NLP: **po pierwsze**, aby komunikować się z ludźmi w naturalny, intuicyjny sposób; **po drugie**, aby uczyć się z ogromnych ilości informacji tekstowych; i **po trzecie**, aby rozwijać naukowe zrozumienie samego języka poprzez łączenie narzędzi AI z lingwistyką, psychologią poznawczą i neuronauk.\n",
                "\n",
                "NLP to wcale nie nowa dziedzina. Jej korzenie sięgają 1949 roku, kiedy Claude Shannon i Warren Weaver opracowali pierwszy model N-gramów słów w języku angielskim, kładąc podwaliny pod statystyczne przetwarzanie języka. Podróż kontynuowała model Bag-of-Words (1954), Latent Semantic Indexing (LSI, 1990) i Latent Dirichlet Allocation (LDA, 2002). Ekstrakcja informacji nabrała rozpędu dzięki corocznym konferencjom Message Understanding Conferences (MUC) sponsorowanym przez rząd USA od 1997 roku. Rewolucja deep learningu przyniosła embeddingsy słów (Word2Vec, 2013), rekurencyjne sieci neuronowe, LSTM i jednostki GRU. Zmiana paradygmatu nastąpiła w 2017 roku wraz z przełomowym artykułem \"Attention Is All You Need\", wprowadzającym transformery. Najnowszym osiągnięciem, w 2024 roku, DeepSeek opublikował raporty techniczne o modelach rozumowania trenowanych przez uczenie ze wzmocnieniem, przesuwając granice jeszcze dalej.\n",
                "\n",
                "```mermaid\n",
                "timeline\n",
                "    title Evolution of Natural Language Processing\n",
                "    1949 : N-gram Models (Shannon & Weaver)\n",
                "    1954 : Bag-of-Words\n",
                "    1990 : Latent Semantic Indexing (LSI)\n",
                "    1997 : Message Understanding Conferences (MUC)\n",
                "    2002 : Latent Dirichlet Allocation (LDA)\n",
                "    2013 : Word2Vec & Embeddings\n",
                "    2014-2016 : RNNs, LSTMs, GRUs\n",
                "    2017 : Transformers (\"Attention Is All You Need\")\n",
                "    2024 : Reasoning Models (DeepSeek)\n",
                "```"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "5dd639bb",
            "metadata": {},
            "source": [
                "### 1.1 Dane tekstowe w inżynierii\n",
                "\n",
                "Inżynierowie pracują w świecie nasyconym nieustrukturyzowanym tekstem. Codziennie technicy piszą dzienniki konserwacji opisujące zachowanie urządzeń, menedżerowie sporządzają raporty zmianowe, klienci zgłaszają reklamacje gwarancyjne i opinie, a zespoły projektowe tworzą dokumentację. Ale tekst nie tylko wypływa z inżynierii, a otacza inżynierów na każdym kroku.\n",
                "\n",
                "Rozważmy typowe środowisko inżynierskie: **normy i specyfikacje** definiują, co należy zbudować; **Standardowe Procedury Operacyjne (SOP)** dyktują, jak wykonywać pracę; **transkrypcje spotkań** z klientami lub zarządem zawierają wymagania i ograniczenia. Inżynierowie analizują **raporty z testów prototypów**, analizują **reklamacje klientów** i studiują **dokumenty patentowe**, które służą jako plany rozwiązywania problemów w różnych branżach. Dokumentacja techniczna przechowuje dziesięciolecia wiedzy instytucjonalnej o trybach awarii, decyzjach projektowych i skutecznych rozwiązaniach.\n",
                "\n",
                "To bogactwo informacji tekstowych stanowi zarówno szansę, jak i wyzwanie. NLP umożliwia inżynierom:\n",
                "\n",
                "- Automatyczne przetwarzanie i kategoryzowanie dzienników konserwacji\n",
                "- Wydobywanie spostrzeżeń z opinii klientów na dużą skalę\n",
                "- Przeszukiwanie rozległych archiwów technicznych w poszukiwaniu odpowiednich precedensów\n",
                "- Interfejsowanie z narzędziami inżynierskimi za pomocą języka naturalnego\n",
                "- Konwersję mowy na tekst dla dokumentacji bez użycia rąk\n",
                "\n",
                "```mermaid\n",
                "graph TD\n",
                "    A[Engineering Text Sources] --> B[Internal Sources]\n",
                "    A --> C[External Sources]\n",
                "    A --> D[Documentation]\n",
                "\n",
                "    B --> B1[Maintenance Logs]\n",
                "    B --> B2[Shift Reports]\n",
                "    B --> B3[Meeting Transcripts]\n",
                "    B --> B4[Test Reports]\n",
                "\n",
                "    C --> C1[Customer Feedback]\n",
                "    C --> C2[Warranty Claims]\n",
                "    C --> C3[Complaint Forms]\n",
                "    C --> C4[Patent Documents]\n",
                "\n",
                "    D --> D1[Standards & Specs]\n",
                "    D --> D2[SOPs]\n",
                "    D --> D3[Design Documentation]\n",
                "    D --> D4[Technical Manuals]\n",
                "```\n",
                "\n",
                "### 1.2 NLP w przepływie pracy inżynierskiej\n",
                "\n",
                "NLP stał się istotnym komponentem nowoczesnych systemów wspomagania decyzji inżynierskich. Zamiast ręcznie przeszukiwać tysiące dzienników konserwacji lub recenzji klientów, inżynierowie mogą wykorzystać NLP do wyodrębniania wzorców, identyfikowania powtarzających się awarii i priorytetyzacji problemów według wagi i częstotliwości.\n",
                "\n",
                "**Typowe zastosowania NLP w inżynierii obejmują:**\n",
                "\n",
                "- **Wykrywanie i diagnostyka usterek**: Automatyczna analiza dzienników techników w celu identyfikacji problemów z urządzeniami zanim się nasilą\n",
                "- **Analiza opinii klientów**: Przetwarzanie recenzji i reklamacji w celu odkrywania słabości projektowych lub próśb o nowe funkcje\n",
                "- **Wyszukiwanie dokumentacji**: Przeszukiwanie instrukcji technicznych i historycznych zapisów za pomocą podobieństwa semantycznego zamiast dokładnego dopasowania słów kluczowych\n",
                "- **Automatyczne raportowanie**: Generowanie podsumowań działań konserwacji prewencyjnej\n",
                "- **Interfejsy głosowe**: Użycie mowy na tekst do dokumentowania ustaleń bez użycia rąk w terenie oraz tekstu na mowę dla dostępności\n",
                "\n",
                "Tradycyjne wyszukiwanie oparte na słowach kluczowych zawodzi, gdy inżynierowie muszą znaleźć koncepcyjnie podobne awarie lub gdy terminologia różni się między zespołami. **Wyszukiwanie oparte na embeddingach** — które zgłębimy szczegółowo — umożliwia znajdowanie semantycznie powiązanych treści nawet gdy używane są różne słowa. Na przykład, wyszukiwanie \"wibracji łożyska\" może wydobyć dzienniki o \"oscylacji wału\" lub \"wyważeniu wirnika\", ponieważ te koncepcje są blisko powiązane znaczeniowo."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "d7c9620a",
            "metadata": {},
            "source": [
                "## 2. Dlaczego język naturalny jest trudny\n",
                "\n",
                "Język naturalny jest fundamentalnie wyzwaniem dla komputerów, ponieważ ewoluował dla komunikacji międzyludzkiej, a nie przetwarzania maszynowego. W przeciwieństwie do języków programowania z ścisłą składnią i jednoznacznym znaczeniem, język ludzki jest nieuporządkowany, zależny od kontekstu i pełen ukrytej wiedzy. W zastosowaniach inżynierskich te wyzwania są wzmocnione przez żargon techniczny, skróconą notację i nieformalny styl dokumentacji terenowej.\n",
                "\n",
                "**Niejednoznaczność i polisemia**: Słowa często mają wiele znaczeń w zależności od kontekstu. W inżynierii słowo \"łożysko\" może odnosić się do komponentu mechanicznego, pomiaru kierunkowego lub nośności obciążenia. \"Uszczelnienie\" może oznaczać uszczelkę lub powłokę. \"Pęknięcie\" może opisywać złamanie, dźwięk słyszalny lub akt rozwiązywania problemu. Bez kontekstu maszyny mają trudności z określeniem, które znaczenie ma zastosowanie.\n",
                "\n",
                "**Pragmatyka i skróty techników**: Technicy terenu rzadko piszą w pełnych zdaniach. Dziennik konserwacji może brzmieć \"pompa #3 głośna, sprawdz łożyska OK, mzl kawitacja\" — skrótowo, nieformalnie i wymagająco wiedzy dziedzinowej do interpretacji. Znaczenie zależy nie tylko od słów, ale od wspólnego zrozumienia procedur konserwacji i zachowania urządzeń.\n",
                "\n",
                "**Kwantyfikacja, czas i modalność**: Język inżynierski jest pełen niejasnych kwantyfikatorów i niepewności. Wyrażenia takie jak \"nieco wyższa temperatura\", \"zauważalna wibracja\" lub \"może wkrótce zawieść\" są subiektywne i zależne od kontekstu. Co liczy się jako \"nieco wyższa\" zależy od normalnych warunków pracy. \"Może zawieść\" wyraża niepewność co do przyszłych wydarzeń. Odniesienia czasowe jak \"sprawdzono wczoraj\" lub \"działa gorąco od wtorku\" wymagają śledzenia czasu i powiązania wydarzeń chronologicznie.\n",
                "\n",
                "**Zależności długodystansowe**: W piśmie technicznym relacje przyczynowo-skutkowe często obejmują wiele zdań, a nawet akapitów. Technik może opisać objawy w jednym zdaniu, podjęte działania w innym, a wyniki w trzecim. Zrozumienie wymaga połączenia informacji w całej narracji: \"Silnik przegrzewał się. Wyczyszczono filtry. Temperatura się znormalizowała.\" Ukryte połączenie — że czyszczenie filtrów rozwiązało przegrzewanie — nie jest wyrażone wprost.\n",
                "\n",
                "**Żargon specyficzny dla dziedziny**: Każda dyscyplina inżynierska ma wyspecjalizowane słownictwo i skróty. \"FFT\", \"RMS\", \"EOL\", \"MTBF\", \"SOP\" — nie znaczą nic poza swoim kontekstem technicznym. Co gorsza, ten sam skrót może oznaczać różne rzeczy w różnych dziedzinach. \"PSI\" może być funtami na cal kwadratowy w jednej dziedzinie i inspekcją przed wysyłką w innej. Systemy NLP muszą być trenowane na korpusach specyficznych dla dziedziny, aby poprawnie obsługiwać tę terminologię."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "deb5d536",
            "metadata": {},
            "source": [
                "## 3. Ewolucja algorytmów NLP\n",
                "\n",
                "### 3.1 Klasyczne NLP: Bag of Words\n",
                "\n",
                "Najwcześniejsze podejście obliczeniowe do tekstu było niezwykle proste: policzyć słowa. Model **Bag-of-Words (BoW)** traktuje dokument jako nieuporządkowany zbiór słów, całkowicie ignorując gramatykę i kolejność słów. Każdy dokument staje się wektorem liczników słów.\n",
                "\n",
                "```mermaid\n",
                "graph LR\n",
                "    A[\"Motor vibration excessive\"] --> B[Tokenize]\n",
                "    B --> C[\"['motor', 'vibration', 'excessive']\"]\n",
                "    C --> D[Count]\n",
                "    D --> E[\"{'motor': 1, 'vibration': 1, 'excessive': 1}\"]\n",
                "```\n",
                "\n",
                "Udoskonaleniem zwanym **TF-IDF** (Term Frequency-Inverse Document Frequency) jest ważenie słów według ich wyróżnialności: typowe słowa jak \"the\" otrzymują niskie wagi, podczas gdy rzadkie terminy techniczne otrzymują wysokie wagi. To pomaga identyfikować dokumenty o określonych tematach.\n",
                "\n",
                "### 3.2 Ograniczenia klasycznych podejść\n",
                "\n",
                "Bag-of-Words katastrofalnie zawodzi na tekście inżynierskim:\n",
                "\n",
                "- **Brak semantyki**: \"łożysko uległo awarii\" i \"łożysko działa normalnie\" zawierają te same słowa, ale przeciwne znaczenia\n",
                "- **Brak kolejności słów**: \"pompa uszkodziła silnik\" vs \"silnik uszkodził pompę\" są traktowane identycznie\n",
                "- **Brak kontekstu**: \"uszczelnienie\" jako komponent i \"uszczelnienie\" jako czasownik są nieodróżnialne\n",
                "- **Rzadkie wektory**: Większość słów pojawia się w niewielu dokumentach, tworząc ogromne, głównie zerowe wektory\n",
                "- **Brak podobieństwa**: \"wibracja\" i \"oscylacja\" są traktowane jako całkowicie niepowiązane słowa pomimo bycia blisko-synonimami\n",
                "\n",
                "Te ograniczenia czynią BoW nieodpowiednim do wyszukiwania semantycznego. Znajdowanie podobnych awarii wymaga zrozumienia znaczenia, nie tylko dopasowania słów kluczowych.\n",
                "\n",
                "### 3.3 Nowoczesne NLP: Embeddingsy\n",
                "\n",
                "Przełom nastąpił wraz z **embeddingsami słów**: gęstymi, niskodymensjonalnymi wektorami, które uchwytują znaczenie semantyczne. Zamiast rzadkich wektorów liczników słów, każde słowo (lub fraza, lub zdanie) jest reprezentowane jako punkt w ciągłej przestrzeni wektorowej — zazwyczaj 300-768 wymiarów. Słowa o podobnych znaczeniach grupują się razem w tej przestrzeni.\n",
                "\n",
                "**Embeddingsy słów** są uczone przez trenowanie sieci neuronowych na ogromnych korpusach tekstowych. Sieci uczą się przewidywać słowa z kontekstu, a w procesie odkrywają, że \"wibracja\" i \"oscylacja\" pojawiają się w podobnych kontekstach i powinny mieć podobne reprezentacje. Nowoczesne modele oparte na transformerach jak BERT i GPT idą dalej, tworząc **embeddingsy kontekstowe**, gdzie to samo słowo otrzymuje różne wektory w zależności od użycia.\n",
                "\n",
                "**t-SNE (t-Distributed Stochastic Neighbor Embedding)** to technika redukcji wymiarowości, która projektuje wysokodymensjonalne embeddingsy do 2D lub 3D dla wizualizacji. Zachowuje strukturę lokalną: punkty, które są blisko w przestrzeni wysokodymensjonalnej, pozostają blisko w wizualizacji."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "36e4a9a5",
            "metadata": {},
            "outputs": [],
            "source": [
                "from sentence_transformers import SentenceTransformer\n",
                "import numpy as np\n",
                "from sklearn.metrics.pairwise import cosine_similarity\n",
                "\n",
                "# Load a pre-trained embedding model\n",
                "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
                "\n",
                "# Engineering analogy: motor : electric :: pump : ?\n",
                "words = [\n",
                "    \"motor\",\n",
                "    \"electric motor\",\n",
                "    \"pump\",\n",
                "    \"electric pump\",\n",
                "    \"hydraulic pump\",\n",
                "    \"diesel engine\",\n",
                "    \"electric generator\",\n",
                "]\n",
                "\n",
                "# Generate embeddings\n",
                "embeddings = model.encode(words, device='cpu')\n",
                "\n",
                "# Calculate: \"electric motor\" - \"motor\" + \"pump\"\n",
                "motor_vec = embeddings[0]\n",
                "electric_motor_vec = embeddings[1]\n",
                "pump_vec = embeddings[2]\n",
                "\n",
                "# The \"electric\" concept vector\n",
                "electric_concept = electric_motor_vec - motor_vec\n",
                "\n",
                "# Add it to pump\n",
                "result_vec = pump_vec + electric_concept\n",
                "\n",
                "# Find closest match\n",
                "similarities = cosine_similarity([result_vec], embeddings)[0]\n",
                "most_similar_idx = np.argmax(similarities)\n",
                "\n",
                "print(f\"motor : electric motor :: pump : {words[most_similar_idx]}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "a34de496",
            "metadata": {},
            "source": [
                "To demonstruje, że embeddingsy uchwytują relacje koncepcyjne. Arytmetyka wektorowa \"przechwytuje\" koncepcję \"elektrycznego\" i przenosi ją z silników na pompy."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "b0d565bb",
            "metadata": {},
            "source": [
                "### 3.4 Semantyka jako geometria\n",
                "\n",
                "Embeddingsy przekształcają język w geometrię. Podobieństwo semantyczne staje się bliskością przestrzenną: podobne koncepcje grupują się razem, a odległość między punktami odzwierciedla ich różnicę koncepcyjną. Ten widok geometryczny umożliwia potężne możliwości wyszukiwania — możemy znaleźć elementy \"bliskie\" zapytaniu w przestrzeni znaczenia, nawet jeśli nie dzielą żadnych słów kluczowych.\n",
                "\n",
                "Zwizualizujmy tę zasadę. Osadźmy zestaw terminów awarii inżynierskich, zredukujmy je do 2D za pomocą t-SNE i zobaczmy, gdzie ląduje zapytanie:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "f2b42bf7",
            "metadata": {},
            "outputs": [],
            "source": [
                "from sentence_transformers import SentenceTransformer\n",
                "from sklearn.manifold import TSNE\n",
                "import matplotlib.pyplot as plt\n",
                "import numpy as np\n",
                "\n",
                "# Load model\n",
                "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
                "\n",
                "# Engineering failure modes (grouped by type)\n",
                "terms = [\n",
                "    # Vibration-related\n",
                "    \"bearing vibration\", \"shaft oscillation\", \"rotor imbalance\", \"resonance\",\n",
                "    # Thermal-related\n",
                "    \"overheating\", \"high temperature\", \"thermal expansion\", \"cooling failure\",\n",
                "    # Lubrication-related\n",
                "    \"oil contamination\", \"insufficient lubrication\", \"grease degradation\",\n",
                "    # Structural-related\n",
                "    \"crack propagation\", \"material fatigue\", \"corrosion\", \"deformation\"\n",
                "]\n",
                "\n",
                "# Query\n",
                "query = \"vibration problem\"\n",
                "\n",
                "# Embed all terms + query\n",
                "all_texts = terms + [query]\n",
                "embeddings = model.encode(all_texts, device='cpu')\n",
                "\n",
                "# Reduce to 2D with t-SNE\n",
                "tsne = TSNE(n_components=2, random_state=42, perplexity=5)\n",
                "coords_2d = tsne.fit_transform(embeddings)\n",
                "\n",
                "# Separate query from terms\n",
                "term_coords = coords_2d[:-1]\n",
                "query_coord = coords_2d[-1]\n",
                "\n",
                "# Plot\n",
                "plt.figure(figsize=(6, 6))\n",
                "plt.scatter(term_coords[:, 0], term_coords[:, 1], c='blue', label='Failure modes', alpha=0.6)\n",
                "plt.scatter(query_coord[0], query_coord[1], c='red', s=200, marker='*', label='Query', edgecolors='black', linewidths=2)\n",
                "\n",
                "# Annotate points\n",
                "for i, term in enumerate(terms):\n",
                "    plt.annotate(term, (term_coords[i, 0], term_coords[i, 1]), fontsize=8, alpha=0.7)\n",
                "plt.annotate(query, (query_coord[0], query_coord[1]), fontsize=10, fontweight='bold', color='red')\n",
                "\n",
                "plt.xlabel('t-SNE Dimension 1')\n",
                "plt.ylabel('t-SNE Dimension 2')\n",
                "plt.title('Semantic Space of Engineering Failure Modes')\n",
                "plt.legend()\n",
                "plt.grid(True, alpha=0.3)\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "128eac6f",
            "metadata": {},
            "source": [
                "## 4. Typowe zadania NLP\n",
                "\n",
                "Teraz, gdy rozumiemy embeddingsy, zbadajmy typowe zadania NLP, które inżynierowie mogą wykorzystać. Każde zadanie adresuje inny aspekt rozumienia tekstu. Zademonstrujemy je za pomocą prostych, praktycznych przykładów."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "b0f444fb",
            "metadata": {},
            "source": [
                "### 4.1 Klasyfikacja tekstu\n",
                "\n",
                "**Czym to jest:** Przypisywanie predefiniowanych kategorii lub etykiet do tekstu. Na przykład, klasyfikacja opinii klientów jako pozytywnych/negatywnych, lub e-maili jako spam/nie spam.\n",
                "\n",
                "**Zastosowanie inżynierskie:** Kategoryzacja raportów konserwacji według wagi (krytyczne, umiarkowane, pomniejsze) lub według systemu, którego dotyczą (elektryczny, mechaniczny, hydrauliczny)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "18758cd0",
            "metadata": {},
            "outputs": [],
            "source": [
                "from transformers import pipeline\n",
                "\n",
                "# Zero-shot classifier\n",
                "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\", device=\"cpu\")\n",
                "\n",
                "# A maintenance log entry\n",
                "text = \"Excessive vibration detected in gearbox housing, possible bearing wear\"\n",
                "\n",
                "# Candidate categories (we just make these up!)\n",
                "candidate_labels = [\"vibration issue\", \"thermal issue\", \"lubrication issue\", \"electrical issue\"]\n",
                "\n",
                "# Classify\n",
                "result = classifier(text, candidate_labels)\n",
                "\n",
                "print(f\"Text: {text}\\n\")\n",
                "for label, score in zip(result[\"labels\"], result[\"scores\"]):\n",
                "    print(f\"{label}: {score:.3f}\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "7bd52b48",
            "metadata": {},
            "source": [
                "### 4.2 Rozpoznawanie nazwanych encji (NER)\n",
                "\n",
                "**Czym to jest:** Identyfikacja i wyodrębnianie specyficznych encji (nazw, dat, lokalizacji, organizacji) z tekstu.\n",
                "\n",
                "**Zastosowanie inżynierskie:** Wyodrębnianie nazw komponentów, numerów części, dat i pomiarów z dzienników konserwacji lub dokumentacji technicznej."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "292de383",
            "metadata": {},
            "outputs": [],
            "source": [
                "from transformers import pipeline\n",
                "\n",
                "# Load NER pipeline with a popular model (BERT-base)\n",
                "ner = pipeline(\n",
                "    \"ner\",\n",
                "    model=\"dslim/bert-base-NER\",\n",
                "    aggregation_strategy=\"simple\",\n",
                "    device=\"cpu\",\n",
                ")\n",
                "\n",
                "# Text with entities\n",
                "text = \"The pump manufactured by Siemens was installed in Building 7 on January 15, 2024.\"\n",
                "\n",
                "# Extract entities\n",
                "entities = ner(text)\n",
                "\n",
                "print(f\"Text: {text}\\n\")\n",
                "for entity in entities:\n",
                "    print(f\"{entity['entity_group']}: {entity['word']} (confidence: {entity['score']:.3f})\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "e44b4594",
            "metadata": {},
            "source": [
                "### 4.3 Analiza sentymentu\n",
                "\n",
                "**Czym to jest:** Określanie emocjonalnego tonu tekstu (pozytywny, negatywny, neutralny).\n",
                "\n",
                "**Zastosowanie inżynierskie:** Analizowanie reklamacji klientów w celu priorytetyzacji problemów, lub ocena pewności technika w rekomendacjach naprawczych (\"prawdopodobnie w porządku\" vs \"zdecydowanie wymaga wymiany\")."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "9d325c03",
            "metadata": {},
            "outputs": [],
            "source": [
                "from transformers import pipeline\n",
                "\n",
                "# Sentiment analyzer\n",
                "sentiment_analyzer = pipeline(\"sentiment-analysis\", device=\"cpu\")\n",
                "\n",
                "# Engineering-flavored feedback\n",
                "feedback = [\n",
                "    \"The new cooling system works great, much quieter than before\",\n",
                "    \"This design is terrible, constant failures every week\",\n",
                "    \"The equipment meets specifications\",\n",
                "    \"Extremely satisfied with the upgraded controls\",\n",
                "]\n",
                "\n",
                "for text in feedback:\n",
                "    result = sentiment_analyzer(text)[0]\n",
                "    print(f\"Feedback: {text}\")\n",
                "    print(f\"Sentiment: {result['label']}, Score: {result['score']:.3f}\\n\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "445e926c",
            "metadata": {},
            "source": [
                "## 5. RAG: Retrieval-Augmented Generation\n",
                "\n",
                "**Wymagania wstępne:** Przed przystąpieniem do tej sekcji upewnij się, że masz:\n",
                "\n",
                "- Zainstalowane i działające Ollama\n",
                "- Pobrany model `gemma3:4b` (`ollama pull gemma3:4b`)\n",
                "\n",
                "### 5.1 Podstawowa interakcja z LLM przy użyciu Pydantic AI\n",
                "\n",
                "Zanim zbudujemy system RAG, najpierw zrozumijmy, jak komunikować się z LLM przy użyciu Pydantic AI. Ta biblioteka zapewnia czysty, pythoniczny interfejs do pracy z modelami językowymi."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "e516913c",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "from dotenv import load_dotenv\n",
                "from pydantic_ai import Agent\n",
                "import nest_asyncio\n",
                "\n",
                "# Allow nested event loops in Jupyter\n",
                "nest_asyncio.apply()\n",
                "\n",
                "load_dotenv()\n",
                "\n",
                "os.environ[\"OLLAMA_BASE_URL\"] = \"http://127.0.0.1:11434/v1\"\n",
                "# Ollama doesn't require an API key, but pydantic_ai might need it set\n",
                "os.environ[\"OLLAMA_API_KEY\"] = \"ollama\"\n",
                "\n",
                "# Create an agent connected to Ollama\n",
                "agent = Agent(\n",
                "    \"ollama:qwen3:4b\",\n",
                "    instructions=\"Be concise, reply with one sentence.\",\n",
                ")\n",
                "\n",
                "# Run a simple query\n",
                "result = agent.run_sync('Where does \"hello world\" come from?')\n",
                "print(result.output)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "dcbedf43",
            "metadata": {},
            "source": [
                "### 5.2 Koncepcja RAG\n",
                "\n",
                "**Retrieval-Augmented Generation (RAG)** łączy moc wyszukiwania semantycznego z generacją LLM. Przepływ pracy to:\n",
                "\n",
                "1. **Wyszukiwanie**: Dla zapytania użytkownika, znajdź najbardziej istotne dokumenty z bazy wiedzy używając podobieństwa embeddingów\n",
                "2. **Wzbogacenie**: Dodaj pobrane dokumenty jako kontekst do promptu\n",
                "3. **Generacja**: LLM generuje odpowiedź ugruntowaną w pobranych faktach\n",
                "\n",
                "**Dlaczego RAG jest ważny dla inżynierów:** LLMy mają ogólną wiedzę, ale nie znają Twoich konkretnych urządzeń, awarii ani procedur. RAG pozwala przeszukiwać historię konserwacji Twojej organizacji, dokumenty techniczne lub decyzje projektowe tak, jakbyś rozmawiał z ekspertem, który przeczytał wszystko.\n",
                "\n",
                "```mermaid\n",
                "graph LR\n",
                "    A[User Query] --> B[Embed Query]\n",
                "    B --> C[Search Knowledge Base]\n",
                "    C --> D[Retrieve Top-K Docs]\n",
                "    D --> E[Construct Prompt with Context]\n",
                "    E --> F[LLM Generate Answer]\n",
                "    F --> G[Grounded Response]\n",
                "```\n",
                "\n",
                "### 5.3 Baza wiedzy: Syntetyczne dzienniki konserwacji\n",
                "\n",
                "Do tej demonstracji użyjemy realistycznych dzienników konserwacji obejmujących typowe tryby awarii. W praktyce mogą one pochodzić z Twojego CMMS, raportów techników lub historycznych zapisów."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "d0646a0d",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Synthetic maintenance logs from a manufacturing facility\n",
                "logs = [\n",
                "    \"Pump #3 shaft vibration excessive at 8mm/s, bearing replacement recommended\",\n",
                "    \"Motor overheating, measured 95°C under normal load, cooling fan obstructed\",\n",
                "    \"Gearbox oil contaminated with metal particles, suspect gear wear\",\n",
                "    \"Conveyor belt slipping, tension adjustment needed\",\n",
                "    \"Hydraulic cylinder leaking from rod seal, seal replacement required\",\n",
                "    \"Compressor making loud knocking sound, possible valve failure\",\n",
                "    \"Temperature sensor reading 20°C too high, calibration required\",\n",
                "    \"Pump cavitation detected, suction line pressure too low\",\n",
                "    \"Bearing noise increasing, vibration spectrum shows inner race defect\",\n",
                "    \"Control panel display flickering, loose connection in power supply\",\n",
                "    \"Lubrication system low pressure, filter clogged\",\n",
                "    \"Shaft misalignment detected, coupling wear visible\",\n",
                "    \"Cooling system flow reduced, heat exchanger tubes partially blocked\",\n",
                "    \"Electrical motor drawing excess current, winding insulation degraded\",\n",
                "    \"Pneumatic actuator slow response, air line restriction suspected\",\n",
                "]\n",
                "\n",
                "print(f\"Knowledge base: {len(logs)} maintenance logs\")\n",
                "for i, log in enumerate(logs[:3]):\n",
                "    print(f\"{i + 1}. {log}\")\n",
                "print(\"...\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "b768c0d8",
            "metadata": {},
            "source": [
                "### 5.4 Krok 1: Osadzanie bazy wiedzy\n",
                "\n",
                "Użyjemy sentence-transformers do konwersji każdego dziennika na gęstą reprezentację wektorową. Te embeddingsy uchwytują znaczenie semantyczne, więc podobne awarie będą miały podobne wektory."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "6b274ff9",
            "metadata": {},
            "outputs": [],
            "source": [
                "from sentence_transformers import SentenceTransformer\n",
                "import numpy as np\n",
                "\n",
                "# Load embedding model\n",
                "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
                "\n",
                "# Embed all logs\n",
                "log_embeddings = model.encode(logs, device='cpu')\n",
                "\n",
                "print(f\"Embedded {len(logs)} logs\")\n",
                "print(f\"Each embedding is a vector of shape: {log_embeddings.shape}\")\n",
                "print(f\"Example embedding (first 5 dimensions): {log_embeddings[0][:5]}\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "4bdcdd46",
            "metadata": {},
            "source": [
                "### 5.5 Krok 2: Wyszukiwanie semantyczne (Retrieval)\n",
                "\n",
                "Gdy użytkownik zadaje pytanie, osadzamy jego zapytanie i znajdujemy najbardziej podobne dzienniki używając podobieństwa cosinusowego."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "8fbf7cd8",
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.metrics.pairwise import cosine_similarity\n",
                "\n",
                "# User query\n",
                "query = \"Why is the pump vibrating?\"\n",
                "\n",
                "# Embed the query\n",
                "query_embedding = model.encode([query])\n",
                "\n",
                "# Calculate similarity between query and all logs\n",
                "similarities = cosine_similarity(query_embedding, log_embeddings)[0]\n",
                "\n",
                "# Get top 3 most relevant logs\n",
                "top_k = 3\n",
                "top_indices = np.argsort(similarities)[-top_k:][::-1]\n",
                "\n",
                "print(f\"Query: {query}\\n\")\n",
                "print(\"Top 3 relevant logs:\")\n",
                "for i, idx in enumerate(top_indices, 1):\n",
                "    print(f\"{i}. [Score: {similarities[idx]:.3f}] {logs[idx]}\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "e62db3ea",
            "metadata": {},
            "source": [
                "### 5.6 Krok 3: Generowanie bez kontekstu (Baseline)\n",
                "\n",
                "Najpierw zobaczmy, co się dzieje, gdy zadajemy pytanie bezpośrednio LLM, bez żadnego pobranego kontekstu. Odpowiedź będzie ogólna i potencjalnie niepoprawna."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "e70ef2ef",
            "metadata": {},
            "outputs": [],
            "source": [
                "from pydantic_ai import Agent\n",
                "\n",
                "# Create agent\n",
                "agent = Agent(\n",
                "    \"ollama:qwen3:4b\",\n",
                "    instructions=\"You are a maintenance engineer assistant. Answer questions about equipment failures.\",\n",
                ")\n",
                "\n",
                "# Query without context\n",
                "query = \"Why is the pump vibrating?\"\n",
                "result = agent.run_sync(query)\n",
                "\n",
                "print(\"=\" * 60)\n",
                "print(\"BASELINE (No RAG):\")\n",
                "print(\"=\" * 60)\n",
                "print(f\"Query: {query}\")\n",
                "print(f\"Answer: {result.output}\")\n",
                "print(\"=\" * 60)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "4f25c74e",
            "metadata": {},
            "source": [
                "### 5.7 Krok 4: Generowanie z kontekstem (RAG)\n",
                "\n",
                "Teraz dostarczamy pobrane dzienniki jako kontekst. LLM może ugruntować swoją odpowiedź w rzeczywistej historii konserwacji."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "044b8690",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Retrieve relevant logs (from step 5.5)\n",
                "top_k = 3\n",
                "top_indices = np.argsort(similarities)[-top_k:][::-1]\n",
                "relevant_logs = [logs[idx] for idx in top_indices]\n",
                "\n",
                "# Construct context\n",
                "context = \"\\n\".join([f\"- {log}\" for log in relevant_logs])\n",
                "\n",
                "# Create RAG prompt\n",
                "rag_prompt = f\"\"\"Based on the following maintenance logs, answer the question:\n",
                "\n",
                "Maintenance Logs:\n",
                "{context}\n",
                "\n",
                "Question: {query}\n",
                "\n",
                "Provide a specific answer based on the logs above.\"\"\"\n",
                "\n",
                "# Query with context\n",
                "result_rag = agent.run_sync(rag_prompt)\n",
                "\n",
                "print(\"\\n\" + \"=\" * 60)\n",
                "print(\"WITH RAG:\")\n",
                "print(\"=\" * 60)\n",
                "print(f\"Query: {query}\")\n",
                "print(\"\\nRetrieved Context:\")\n",
                "for i, log in enumerate(relevant_logs, 1):\n",
                "    print(f\"  {i}. {log}\")\n",
                "print(f\"\\nAnswer: {result_rag.output}\")\n",
                "print(\"=\" * 60)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "f52153f7",
            "metadata": {},
            "source": [
                "### 5.8 Porównanie i dyskusja\n",
                "\n",
                "**Kluczowe obserwacje:**\n",
                "\n",
                "1. **Baseline (bez RAG):** Ogólna odpowiedź wspominająca typowe przyczyny takie jak niewspółosiowość, niewyważenie czy zużycie. Może być technicznie poprawna, ale nie specyficzna dla Twojego urządzenia.\n",
                "\n",
                "2. **Z RAG:** Odpowiedź odnosi się do konkretnych dzienników, wspominając rekomendacje wymiany łożyska, pomiary wibracji wału (8mm/s) lub defekty łożysk wykryte w analizie wibracji. Odpowiedź jest ugruntowana w danych historycznych.\n",
                "\n",
                "## 6. Podsumowanie i kolejne kroki\n",
                "\n",
                "Omówiliśmy podstawowy zestaw narzędzi NLP dla inżynierów, przechodząc od podstawowych koncepcji do kompletnego systemu RAG:\n",
                "\n",
                "1. **Embeddingsy** przekształcają tekst w przestrzeń geometryczną, gdzie podobieństwo semantyczne staje się mierzalną odległością\n",
                "2. **Typowe zadania NLP** (klasyfikacja, NER, analiza sentymentu) dostarczają elementów składowych do rozumienia tekstu\n",
                "3. **RAG** łączy wyszukiwanie i generację, pozwalając przeszukiwać wiedzę organizacyjną przy użyciu języka naturalnego\n",
                "\n",
                "**Zasoby:**\n",
                "\n",
                "- Sentence Transformers: <https://www.sbert.net/>\n",
                "- Pydantic AI: <https://ai.pydantic.dev/>\n",
                "- Hugging Face Transformers: <https://huggingface.co/docs/transformers/>"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "5beeb219",
            "metadata": {},
            "source": [
                "## 6. Summary & Next Steps\n",
                "\n",
                "We've covered the essential NLP toolkit for engineers, progressing from basic concepts to a complete RAG system:\n",
                "\n",
                "1. **Embeddings** transform text into geometric space where semantic similarity becomes measurable distance\n",
                "2. **Common NLP tasks** (classification, NER, sentiment analysis) provide building blocks for text understanding\n",
                "3. **RAG** combines retrieval and generation, letting you query organizational knowledge using natural language\n",
                "\n",
                "**Next Steps for Your Projects:**\n",
                "\n",
                "- **Start small**: Build a RAG system over your team's maintenance logs or design documents\n",
                "- **Experiment with embeddings**: Try different models (all-MiniLM-L6-v2 is fast; all-mpnet-base-v2 is more accurate)\n",
                "- **Refine retrieval**: Experiment with top-k values, hybrid search (combining keyword + semantic), or re-ranking\n",
                "- **Evaluate quality**: Have domain experts review RAG outputs, iterate on prompt engineering\n",
                "- **Scale up**: Move from toy datasets to production databases, add caching, implement feedback loops\n",
                "\n",
                "**Resources:**\n",
                "- Sentence Transformers: https://www.sbert.net/\n",
                "- Pydantic AI: https://ai.pydantic.dev/\n",
                "- Hugging Face Transformers: https://huggingface.co/docs/transformers/"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "python-for-engineers",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.14"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
