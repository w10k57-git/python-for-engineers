{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7590010d",
   "metadata": {},
   "source": [
    "# Laboratorium 5: zadanie klasyfikacji binarnej (ML)\n",
    "\n",
    "Celem tego laboratorium jest wytrenowanie, ewaluacja i optymalizacja klasyfikatora binarnego, z wykorzystaniem Scikit Learn. \n",
    "\n",
    "**Do zaliczenia laboratorium, konieczne jest przesłanie kompletnego notatnika, zawierającego (1) kod potrzebny do wytrenowania klasyfikatora binarnego, (2) kod do ewaluacji metryk modelu na zbiorach train/test wraz z omówieniem wyników oraz (3) zbiór optymalnych parametrów modelu ze względu na `f1-score`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf4eb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "from pydantic import BaseModel\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a55475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definiowanie ścieżki do zapisu modelu\n",
    "MODEL_DIR = Path(\"../../models\")\n",
    "MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "model_path = MODEL_DIR / \"titanic_rf_model.pkl\"\n",
    "\n",
    "print(f\"Model zostanie zapisany do pliku: {model_path.resolve()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51fcf25c",
   "metadata": {},
   "source": [
    "## Wczytanie danych i ich wstępna analiza\n",
    "\n",
    "W tej sekcji, wczytaj dane do analizy z pliku `titanic.csv` i zapoznaj się z ich strukturą. Zidentyfikuj, ile wartości unikalnych znajduje się w kolumnach, jak rozłożone są dane i jakie informacje możemy pozyskać ze zbioru. Do wczytania danych wykorzystaj funkcję `read_csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86edc5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339d95b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848bd8cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759cec59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "328ee9e8",
   "metadata": {},
   "source": [
    "## Podział danych na dane trenujące i testowe\n",
    "\n",
    "W tej części, podziel dane na zbiory testowe i treningowe w proporcji 20/80, zachowując poniższe cechy: `'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked'`. Wykorzystaj do tego celu funkcję `train_test_split`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d02920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wybór cech i zmiennej docelowej\n",
    "features = \n",
    "X = \n",
    "y = \n",
    "\n",
    "# Podział danych (80/20, stratyfikowany)\n",
    "X_train, X_test, y_train, y_test = \n",
    "\n",
    "print(f\"Zbiór treningowy: {X_train.shape}\")\n",
    "print(f\"Zbiór testowy: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b5807a",
   "metadata": {},
   "source": [
    "## Przetwarzanie danych\n",
    "\n",
    "Na tym etapie, przygotowujemy `pipeline` do transformacji danych wejściowych na potrzeby dalszej analizy i trenowania modeli. Na potrzeby tego laboratorium, kompletna implementacja jest już gotowa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09c7a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podział cech na numeryczne i kategoryczne\n",
    "numeric_features = ['Age', 'SibSp', 'Parch', 'Fare']\n",
    "categorical_features = ['Pclass', 'Sex', 'Embarked']\n",
    "\n",
    "# Pipeline dla cech numerycznych\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Pipeline dla cech kategorycznych\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(drop='first', sparse_output=False))\n",
    "])\n",
    "\n",
    "# Połączenie pipeline'ów\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "print(\"Preprocessor gotowy!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556dbbfb",
   "metadata": {},
   "source": [
    "## Trenowanie modelu\n",
    "\n",
    "Zaczniemy od wyboru algorytmu do klasyfikacji binarnej. Do wyboru mamy:  \n",
    "- regresję logistyczną;\n",
    "- lasy losowe;\n",
    "- prostą sieć neuronową (MLP);\n",
    "- maszynę wektorów nośnych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07413e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.mlp import MLPClassifier\n",
    "\n",
    "model = \n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', model)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a30268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trenowanie modelu\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de1bc4d",
   "metadata": {},
   "source": [
    "## Ewaluacja modelu\n",
    "\n",
    "Na tym etapie, dla wytrenowanego modelu wyznaczymy zbiór metryk ewaluacyjnych w postaci `precision`, `recall`, `accuracy` oraz `f1-score`. W tym celu, przypisz do zmiennych `yhat_train` oraz `yhat_test` predykcje modelu dla obu zbiorów danych. Następnie, wykorzystaj przygotowane funkcje do wyznaczenia metryk oraz wyświetl macierz pomyłek dla zbioru trenującego. \n",
    "\n",
    "**UWAGA**. W polu `markdown` pod wynikami opisz otrzymane wyniki, odnosząc się do zagadnienia wysokiej wariancji i stronniczości modelu (_overfitting_ i _underfitiing_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4f5e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationMetrics(BaseModel):\n",
    "    \"\"\"Metryki klasyfikacji\"\"\"\n",
    "    accuracy: float\n",
    "    precision: float\n",
    "    recall: float\n",
    "    f1: float\n",
    "    \n",
    "    def display(self, title: str = \"Metryki\"):\n",
    "        \"\"\"Wyświetl metryki w czytelnej formie\"\"\"\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"{title}\")\n",
    "        print(f\"{'='*50}\")\n",
    "        print(f\"Accuracy:  {self.accuracy:.4f}\")\n",
    "        print(f\"Precision: {self.precision:.4f}\")\n",
    "        print(f\"Recall:    {self.recall:.4f}\")\n",
    "        print(f\"F1-Score:  {self.f1:.4f}\")\n",
    "\n",
    "\n",
    "def calculate_metrics(y_true: np.ndarray, y_pred: np.ndarray) -> ClassificationMetrics:\n",
    "    \"\"\"Oblicz metryki klasyfikacji\"\"\"\n",
    "    return ClassificationMetrics(\n",
    "        accuracy=accuracy_score(y_true, y_pred),\n",
    "        precision=precision_score(y_true, y_pred),\n",
    "        recall=recall_score(y_true, y_pred),\n",
    "        f1=f1_score(y_true, y_pred)\n",
    "    )\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(y_true: np.ndarray, y_pred: np.ndarray, title: str = \"Confusion Matrix\"):\n",
    "    \"\"\"Narysuj macierz pomyłek\"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Perished', 'Survived'])\n",
    "    disp.plot(cmap='Blues')\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd22647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wyznacz predykcje modelu dla każdego ze zbiorów\n",
    "yhat_train = \n",
    "yhat_test = \n",
    "\n",
    "# Wyznacz metryki modelu dla każdego ze zbiorów\n",
    "train_metrics = \n",
    "test_metrics = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e050450",
   "metadata": {},
   "source": [
    "**WNIOSKI**: ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27cee49",
   "metadata": {},
   "source": [
    "## Optymalizacja modelu\n",
    "\n",
    "W tej sekcji przeprowadzimy optymalizację modelu z wykorzystaniem `GridSearchCV` oraz `RandomSearchCV`. Celem jest zidentyfikowanie najlepszego klasyfikatora, oraz porównanie jego możliwości z pierwotnie wytrenowanym. Naszą metryką optymalizacyjną jest miara `f1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c3c7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parametry do przeszukania\n",
    "param_distributions = {\n",
    "# --- YOUR CODE HERE ---\n",
    "\n",
    "# --- YOUR CODE HERE ---\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    pipeline,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=20,\n",
    "    cv=5,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    scoring='f1'\n",
    ")\n",
    "\n",
    "print(\"Rozpoczynam RandomizedSearchCV...\")\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"\\nNajlepsze parametry: {random_search.best_params_}\")\n",
    "print(f\"Najlepszy wynik CV: {random_search.best_score_:.4f}\")\n",
    "print(f\"Wynik na zbiorze testowym: {random_search.score(X_test, y_test):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246d2553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Węższy zakres parametrów (dostosuj na podstawie wyników RandomizedSearchCV)\n",
    "param_grid = {\n",
    "# --- YOUR CODE HERE ---\n",
    "\n",
    "# --- YOUR CODE HERE ---\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    scoring='f1'\n",
    ")\n",
    "\n",
    "print(\"Rozpoczynam GridSearchCV...\")\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"\\nNajlepsze parametry: {grid_search.best_params_}\")\n",
    "print(f\"Najlepszy wynik CV: {grid_search.best_score_:.4f}\")\n",
    "print(f\"Wynik na zbiorze testowym: {grid_search.score(X_test, y_test):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14c0b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Używamy najlepszego modelu z GridSearchCV\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Predykcje\n",
    "yhat_test_optimized = best_model.predict(X_test)\n",
    "\n",
    "# Metryki\n",
    "optimized_metrics = calculate_metrics(y_test, yhat_test_optimized)\n",
    "optimized_metrics.display(\"Metryki - Zoptymalizowany model\")\n",
    "\n",
    "# Confusion matrix\n",
    "plot_confusion_matrix(y_test, yhat_test_optimized, \"Confusion Matrix - Optimized Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5d3ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zapisywanie modelu do pliku\n",
    "joblib.dump(best_model, model_path)\n",
    "print(f\"Model zapisany w: {model_path.resolve()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a20246",
   "metadata": {},
   "source": [
    "## Wykorzystanie wytrenowanego modelu w praktyce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df12386",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Passenger(BaseModel):\n",
    "    \"\"\"Model danych pasażera\"\"\"\n",
    "    Pclass: int\n",
    "    Sex: str\n",
    "    Age: float\n",
    "    SibSp: int\n",
    "    Parch: int\n",
    "    Fare: float\n",
    "    Embarked: str\n",
    "\n",
    "def predict_survival(model_path: str | Path, passenger: Passenger) -> bool:\n",
    "    model = joblib.load(model_path)\n",
    "    passenger_df = pd.DataFrame([passenger.model_dump()])\n",
    "    prediction = model.predict(passenger_df)[0]\n",
    "    return bool(prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db35cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Przykład 1: Kobieta, pierwsza klasa\n",
    "passenger1 = Passenger(\n",
    "    Pclass=1,\n",
    "    Sex='female',\n",
    "    Age=30,\n",
    "    SibSp=0,\n",
    "    Parch=0,\n",
    "    Fare=100.0,\n",
    "    Embarked='S'\n",
    ")\n",
    "\n",
    "result1 = predict_survival(model_path, passenger1)\n",
    "print(f\"Pasażer 1 (kobieta, 1 klasa): {'PRZEŻYJE ✓' if result1 else 'NIE PRZEŻYJE ✗'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44e4050",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Przykład 2: Mężczyzna, trzecia klasa\n",
    "passenger2 = Passenger(\n",
    "    Pclass=3,\n",
    "    Sex='male',\n",
    "    Age=25,\n",
    "    SibSp=0,\n",
    "    Parch=0,\n",
    "    Fare=7.5,\n",
    "    Embarked='S'\n",
    ")\n",
    "\n",
    "result2 = predict_survival(model_path, passenger2)\n",
    "print(f\"Pasażer 2 (mężczyzna, 3 klasa): {'PRZEŻYJE ✓' if result2 else 'NIE PRZEŻYJE ✗'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38882c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Przykład 3: Dziecko z rodziną\n",
    "passenger3 = Passenger(\n",
    "    Pclass=2,\n",
    "    Sex='female',\n",
    "    Age=5,\n",
    "    SibSp=1,\n",
    "    Parch=2,\n",
    "    Fare=30.0,\n",
    "    Embarked='C'\n",
    ")\n",
    "\n",
    "result3 = predict_survival(model_path, passenger3)\n",
    "print(f\"Pasażer 3 (dziecko z rodziną, 2 klasa): {'PRZEŻYJE ✓' if result3 else 'NIE PRZEŻYJE ✗'}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-analysis-for-engineers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
